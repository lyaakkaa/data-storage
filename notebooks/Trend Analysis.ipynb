{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    df = pd.read_csv(path, parse_dates=['FECHA'], infer_datetime_format=True)\n",
    "    df['CPRECIO'] = df[' CPRECIO '].map(lambda x: x.strip().replace(\",\", \"\"))\n",
    "    df['CPRECIO'] = df['CPRECIO'].convert_objects(convert_numeric=True)\n",
    "    df['COSTOPESOS'] = df[' COSTOPESOS ']\n",
    "    df = df.drop([' CPRECIO ', ' COSTOPESOS '], axis=1)\n",
    "    cols = df.columns.values \n",
    "    cols[-3] = \"YEAR\"\n",
    "    df.columns = cols\n",
    "    return df\n",
    "\n",
    "def read_test_data(path):\n",
    "    df = pd.read_csv(path, parse_dates=['FECHA'], infer_datetime_format=True)\n",
    "    df['CPRECIO'] = df[' CPRECIO ']\n",
    "    df['COSTOPESOS'] = df[' COSTOPESOS ']\n",
    "    df = df.drop([' CPRECIO ', ' COSTOPESOS '], axis=1)\n",
    "    cols = df.columns.values \n",
    "    cols[-3] = \"YEAR\"\n",
    "    df.columns = cols\n",
    "    return df\n",
    "\n",
    "def calculate_extra_cols(df):\n",
    "    df['total_price'] =  df['CPRECIO'] * df['#UNIDADES'] * df['CTIPOCAM01']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = read_data('./BASEVENTAS2010A2015.csv')\n",
    "df = calculate_extra_cols(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets start with the brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cleanup all the spaces\n",
    "df[\"MARCA\"] = df[\"MARCA\"].map(lambda x: x.strip())\n",
    "df[\"IDPRODUCTO\"] = df[\"IDPRODUCTO\"].map(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 5 most important Brands by quantity across 5 years\n",
    "top5 = df.groupby(\"MARCA\")[\"#UNIDADES\"].sum().sort_values(ascending=False)[:5]\n",
    "top5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets check the volume of the top brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ts = df.set_index(\"FECHA\")[[\"#UNIDADES\", \"MARCA\", \"total_price\"]]\n",
    "units_ts = ts[[\"#UNIDADES\", \"MARCA\"]]\n",
    "for brand in top5.index:\n",
    "    new_ts = units_ts[units_ts[\"MARCA\"] == brand][\"#UNIDADES\"]\n",
    "    new_ts = new_ts[\"2013\":].resample(\"3W\").sum()\n",
    "    new_ts.plot(ax=plt.gca(), label=brand, figsize=(12, 8))\n",
    "plt.legend()\n",
    "plt.title(\"Volume per Top Brands\")\n",
    "# brandts.plot(logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 5 brands by price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 5 most important Brands by revenue across 5 years\n",
    "top_b_p = df.groupby(\"MARCA\")[\"total_price\"].sum().sort_values(ascending=False)[:5]\n",
    "top_b_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "revenue_ts = ts[[\"total_price\", \"MARCA\"]]\n",
    "for brand in top_b_p.index[:5]:\n",
    "    new_ts = revenue_ts[units_ts[\"MARCA\"] == brand][\"total_price\"]\n",
    "    new_ts = new_ts[\"2013\":].resample(\"10W\").sum()\n",
    "    new_ts.plot(ax=plt.gca(), label=brand, figsize=(12, 5))\n",
    "plt.legend()\n",
    "# brandts.plot(logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets move to individual products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_top_products(n=5, by=None):\n",
    "    new_df = df[((df[\"IDPRODUCTO\"] != \"FAC_PROY\") | \n",
    "                (df[\"IDPRODUCTO\"] != \"ANTICIPO\") | \n",
    "                (df[\"IDPRODUCTO\"] != \"SERVICIOS\")) &\n",
    "                (df[\"MARCA\"] == \"BANNER\")]\n",
    "    return new_df.groupby([\"IDPRODUCTO\", \"PRODUCTO\"])[by].sum().sort_values(ascending=False)[:n]\n",
    "top_p_q = get_top_products(n=8, by=\"#UNIDADES\") # Top products by units\n",
    "top_p_r = get_top_products(n=8, by=\"total_price\") # Top products by revenue\n",
    "print \"Top products by quantity\", \"\\n\", \"-\"*30\n",
    "print top_p_q, \"\\n\"\n",
    "print \"Top products by revenue\", \"\\n\", \"-\"*30\n",
    "print top_p_r\n",
    "# df.groupby([\"IDPRODUCTO\", \"PRODUCTO\"])[\"#UNIDADES\"].sum()\n",
    "# ts = df.set_index(\"FECHA\")[[\"#UNIDADES\", \"MARCA\", \"total_price\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "ts = df.set_index(\"FECHA\")[[\"#UNIDADES\", \"IDPRODUCTO\", \"total_price\"]]\n",
    "units_ts = ts[[\"#UNIDADES\", \"IDPRODUCTO\"]]\n",
    "test_ts = None\n",
    "for prod_id, product in top_p_q.index[0:1]:\n",
    "    d_range_s = \"2014\"\n",
    "    d_range_e = \"2016\"\n",
    "    resample = \"W\"\n",
    "    new_ts = units_ts[units_ts[\"IDPRODUCTO\"] == prod_id][\"#UNIDADES\"]\n",
    "    plt.figure()\n",
    "    new_ts2 = new_ts[d_range_s:d_range_e].resample(resample).max()\n",
    "    new_ts2.plot(label=product, figsize=(12, 3))\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    new_ts3 = new_ts[d_range_s:d_range_e].resample(resample).mean()\n",
    "    new_ts3.plot(label=product, figsize=(12, 3))\n",
    "    test_ts = np.log(new_ts3)\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "def test_stationarity(timeseries):\n",
    "\n",
    "    #Determing rolling statistics\n",
    "    rolmean = timeseries.rolling(window=12, center=False).mean()\n",
    "    rolstd = timeseries.rolling(window=12, center=False).std()\n",
    "\n",
    "    #Plot rolling statistics:\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    orig = plt.plot(timeseries, color='blue',label='Original')\n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show()\n",
    "    \n",
    "    #Perform Dickey-Fuller test:\n",
    "    print 'Results of Dickey-Fuller Test:'\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print dfoutput \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_stationarity(test_ts.fillna(1))\n",
    "plot_acf_pacf(test_ts.fillna(0), 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_difference = test_ts - test_ts.shift(1)\n",
    "test_stationarity(first_difference.fillna(1))\n",
    "plot_acf_pacf(first_difference.fillna(1), 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seasonal_difference = first_difference - test_ts.shift(11)\n",
    "test_stationarity(seasonal_difference.fillna(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "def plot_acf_pacf(your_data, lags):\n",
    "   fig = plt.figure(figsize=(12,8))\n",
    "   ax1 = fig.add_subplot(211)\n",
    "   fig = plot_acf(your_data, lags=lags, ax=ax1)\n",
    "   ax2 = fig.add_subplot(212)\n",
    "   fig = plot_pacf(your_data, lags=lags, ax=ax2)\n",
    "   plt.show()\n",
    "    \n",
    "plot_acf_pacf(seasonal_difference.fillna(0), 40)\n",
    "# seasonal_difference.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import statsmodels.api as sm\n",
    "# mod = SARIMAX(test_ts, trend='n', order=(0,1,0), seasonal_order=(1,1,1,12))\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from numpy import inf\n",
    "\n",
    "# print model1.summary()\n",
    "# print model2.summary()\n",
    "df2 = read_test_data(\"./BASEVENTAS2016.csv\")\n",
    "ts2 = df2.set_index(\"FECHA\")[\"#UNIDADES\"]\n",
    "ts2 = np.log(ts2.sort_index())\n",
    "ts2[ts2 == -inf] = 0\n",
    "ts2 = pd.DataFrame(ts2.resample(\"W\").mean())\n",
    "df2 = pd.DataFrame(test_ts.fillna(0))\n",
    "new_df = pd.concat([df2, ts2.fillna(1)])\n",
    "\n",
    "model1 = SARIMAX(test_ts, order=(2,1,0), trend='n', time_varying_regression=True,mle_regression=False,  seasonal_order=(1,1,1,11)).fit()\n",
    "model2 = SARIMAX(test_ts, order=(0,1,2), trend='n', time_varying_regression=True,mle_regression=False, seasonal_order=(1,1,1,11)).fit()\n",
    "new_df['model1'] = model1.forecast(steps=20)  \n",
    "new_df['model2'] = model2.forecast(steps=20)  \n",
    "np.exp(new_df[new_df.index > \"2015\"]).plot(figsize=(18,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Calculate metrics of my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_true = new_df[~new_df[\"model1\"].isnull()][\"#UNIDADES\"]\n",
    "y_pred_1 = new_df[~new_df[\"model1\"].isnull()][\"model1\"]\n",
    "y_pred_2 = new_df[~new_df[\"model1\"].isnull()][\"model2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
